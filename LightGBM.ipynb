{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error , r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import gc, sys\n",
    "gc.enable()\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "#        else:\n",
    "#            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_of_data(df, part):\n",
    "    \n",
    "    game = df['game'].unique()\n",
    "    game_part = np.random.choice(game, int(part * len(game)))\n",
    "    \n",
    "    df = df[df['game'].isin(game_part)]\n",
    "    \n",
    "    del game\n",
    "    del game_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def add_new_features_1(df):\n",
    "    \n",
    "    # calculate total distance\n",
    "    #df['totalDistance'] = df['rideDistance'] + df['walkDistance'] + df['swimDistance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_features(df):\n",
    "\n",
    "    # calculate total distance\n",
    "    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n",
    "\n",
    "    df['timeSurvived'] = df['timeSurvived'] \n",
    "    \n",
    "    # calculate total kills and assists\n",
    "    df['kills'] = df['kills'] + (df['assists']/2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df[df == np.Inf] = np.NaN\n",
    "    df[df == np.NINF] = np.NaN\n",
    "    \n",
    "    df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df, is_train=True):\n",
    "      \n",
    "    features = list(df.columns)\n",
    "    if 'winPlacePer' in features:\n",
    "        features.remove('winPlacePer')\n",
    "    \n",
    "    y = None\n",
    "    \n",
    "    # average y for training dataset\n",
    "    if is_train:\n",
    "        y = df.groupby(['game','teamId'])['winPlacePer'].agg('mean')\n",
    "    elif 'winPlacePerc' in df.columns:\n",
    "        y = df['winPlacePerc']\n",
    "    \n",
    "    # Make new features indicating the mean of the features ( grouped by game and teamId ) :\n",
    "    print(\"get group mean feature\")\n",
    "    agg = df.groupby(['game','teamId']).agg('mean')\n",
    "    agg_rank = agg.groupby('game').rank(pct=True).reset_index()\n",
    "    \n",
    "    # If we are processing the training data let df_out = the grouped  'game' and 'teamId'\n",
    "    if is_train:\n",
    "        df_out = agg.reset_index()[['game','teamId']]\n",
    "    # If we are processing the test data let df_out = 'game' and 'teamId' without grouping \n",
    "    else:\n",
    "        df_out = df[['game','teamId']]\n",
    "\n",
    "    # Merge agg and agg_rank (that we got before) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['game', 'teamId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['game', 'teamId'])\n",
    "    \n",
    "    # Make new features indicating the max value of the features for each group ( grouped by game and teamId )\n",
    "    print(\"get group max feature\")\n",
    "    agg = df.groupby(['game','teamId']).agg('max')\n",
    "    agg_rank = agg.groupby('game').rank(pct=True).reset_index()\n",
    "    \n",
    "    # Merge the new (agg and agg_rank) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['game','teamId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['game','teamId'])\n",
    "    \n",
    "    # Make new features indicating the minimum value of the features for each group ( grouped by game and teamId )\n",
    "    print(\"get group min feature\")\n",
    "    agg = df.groupby(['game','teamId']).agg('min')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('game').rank(pct=True).reset_index()\n",
    "    \n",
    "    # Merge the new (agg and agg_rank) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['game','teamId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['game','teamId'])\n",
    "    \n",
    "    # Make new features indicating the number of players in each group ( grouped by game and teamId )\n",
    "    print(\"get group size feature\")\n",
    "    agg = df.groupby(['game','teamId']).size().reset_index(name='group_size')\n",
    "    \n",
    "    # Merge the group_size feature with df_out :\n",
    "    df_out = df_out.merge(agg, how='left', on=['game','teamId'])\n",
    "    \n",
    "    # Make new features indicating the mean value of each features for each match :\n",
    "    print(\"get match mean feature\")\n",
    "    agg = df.groupby(['game']).agg('mean').reset_index()\n",
    "    \n",
    "    # Merge the new agg with df_out :\n",
    "    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['game'])\n",
    "    \n",
    "    # Make new features indicating the number of groups in each match :\n",
    "    print(\"get match size feature\")\n",
    "    agg = df.groupby(['game']).size().reset_index(name='match_size')\n",
    "\n",
    "    # Merge the match_size feature with df_out :\n",
    "    df_out = df_out.merge(agg, how='left', on=['game'])\n",
    "    \n",
    "    # Drop game and teamId\n",
    "    df_out.drop([\"game\",\"teamId\"], axis=1, inplace=True)\n",
    "    \n",
    "    del agg, agg_rank\n",
    "    \n",
    "    return df_out, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator(object):\n",
    "    \n",
    "    def fit(self, x_train, y_train, x_valid, y_valid):\n",
    "        raise NotImplementedException\n",
    "    \n",
    "    def predict(self, x):\n",
    "        raise NotImplementedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScikitLearnEstimator(Estimator):\n",
    "    \n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "    \n",
    "    def fit(self, x_train, y_train, x_valid, y_valid):\n",
    "        self.estimator.fit(x_train, y_train)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.estimator.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_step(estimator, x_train, y_train, train_idx, valid_idx, x_test, oof):\n",
    "    \n",
    "    # prepare train and validation data\n",
    "    x_train_train = x_train[train_idx]\n",
    "    y_train_train = y_train[train_idx]\n",
    "    x_train_valid = x_train[valid_idx]\n",
    "    y_train_valid = y_train[valid_idx]\n",
    "    \n",
    "    # fit estimator\n",
    "    estimator.fit(x_train_train, y_train_train, x_train_valid, y_train_valid)\n",
    "    \n",
    "    # collect OOF\n",
    "    oof_part = estimator.predict(x_train_valid)\n",
    "    \n",
    "    print('MAE:', mean_absolute_error(y_train_valid, oof_part))\n",
    "    oof[valid_idx] = oof_part\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_part = estimator.predict(x_test)\n",
    "    \n",
    "    return y_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(estimator, x_train, y_train, x_test):\n",
    "    \n",
    "    oof = np.zeros(x_train.shape[0])\n",
    "    \n",
    "    y = np.zeros(x_test.shape[0])\n",
    "    \n",
    "    kf = KFold(n_splits=5, random_state=42)\n",
    "    \n",
    "    for train_idx, valid_idx in kf.split(x_train):\n",
    "        \n",
    "        y_part = fit_predict_step(estimator, x_train, y_train, train_idx, valid_idx, x_test, oof)\n",
    "        \n",
    "        # average predictions for test data\n",
    "        y += y_part / kf.n_splits\n",
    "    \n",
    "    print('Final MAE:', mean_absolute_error(y_train, oof))\n",
    "    print('Final MSE:', mean_squared_error(y_train, oof))\n",
    "    print('r2:', r2_score(y_train, oof))\n",
    "    return oof, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_step(estimator, x_train, y_train, train_idx, valid_idx, oof):\n",
    "    \n",
    "    # prepare train and validation data\n",
    "    x_train_train = x_train[train_idx]\n",
    "    y_train_train = y_train[train_idx]\n",
    "    x_train_valid = x_train[valid_idx]\n",
    "    y_train_valid = y_train[valid_idx]\n",
    "    \n",
    "    # fit estimator\n",
    "    estimator.fit(x_train_train, y_train_train, x_train_valid, y_train_valid)\n",
    "    \n",
    "    # collect OOF\n",
    "    oof_part = estimator.predict(x_train_valid)\n",
    "    \n",
    "    mae = mean_absolute_error(y_train_valid, oof_part)\n",
    "    print('MAE:', mae)\n",
    "    \n",
    "    oof[valid_idx] = oof_part\n",
    "    \n",
    "    return estimator, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(estimator, x_train, y_train):\n",
    "    \n",
    "    oof = np.zeros(x_train.shape[0])\n",
    "    \n",
    "    kf = KFold(n_splits=5, random_state=42)\n",
    "    \n",
    "    trained_estimators = []\n",
    "    \n",
    "    for train_idx, valid_idx in kf.split(x_train):\n",
    "        \n",
    "        e, mae = fit_step(estimator, x_train, y_train, train_idx, valid_idx, oof)\n",
    "        \n",
    "        trained_estimators.append(deepcopy(e))\n",
    "    \n",
    "    print('Final MAE:', mean_absolute_error(y_train, oof))\n",
    "    print('Final MSE:', mean_squared_error(y_train, oof))\n",
    "    print('r2:', r2_score(y_train, oof))\n",
    "    return oof, trained_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(trained_estimators, x_test):\n",
    "    \n",
    "    y = np.zeros(x_test.shape[0])\n",
    "    \n",
    "    for estimator in trained_estimators:\n",
    "        \n",
    "        y_part = estimator.predict(x_test)\n",
    "        \n",
    "        # average predictions for test data\n",
    "        y += y_part / len(trained_estimators)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_fit(estimator, df_train, scaler=None):\n",
    "    \n",
    "    # add new features\n",
    "    add_new_features(df_train)\n",
    "    \n",
    "    # feature engineering\n",
    "    x_train, y_train = feature_engineering(df_train, is_train=True)\n",
    "    x_train = reduce_mem_usage(x_train)\n",
    "    gc.collect()\n",
    "    \n",
    "    # scale\n",
    "    if not (scaler is None):\n",
    "        scaler.fit(x_train)\n",
    "        scaled_x_train = scaler.transform(x_train)\n",
    "    else:\n",
    "        scaled_x_train = x_train.values\n",
    "    \n",
    "    del x_train\n",
    "    gc.collect()\n",
    "    \n",
    "    # fit\n",
    "    oof, trained_estimators = fit(estimator, scaled_x_train, y_train.values)\n",
    "    \n",
    "    del scaled_x_train\n",
    "    del y_train\n",
    "    gc.collect()\n",
    "    \n",
    "    return oof, trained_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_predict(trained_estimators, df_test, scaler=None):\n",
    "    \n",
    "    # add new features\n",
    "    add_new_features(df_test)\n",
    "    \n",
    "    # feature engineering\n",
    "    x_test, _ = feature_engineering(df_test, is_train=False)\n",
    "    x_test = reduce_mem_usage(x_test)\n",
    "    gc.collect()\n",
    "    \n",
    "    # scale\n",
    "    if not (scaler is None):\n",
    "        scaled_x_test = scaler.transform(x_test)\n",
    "    else:\n",
    "        scaled_x_test = x_test.values\n",
    "    \n",
    "    del x_test\n",
    "    gc.collect()\n",
    "    \n",
    "    # predict\n",
    "    y = predict(trained_estimators, scaled_x_test)\n",
    "    \n",
    "    del scaled_x_test\n",
    "    gc.collect()\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13432, 24)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('C:/Users/korn/Desktop/TNI/Paper/Code/train_pubg.csv')\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2.46 MB\n",
      "Memory usage after optimization is: 0.40 MB\n",
      "Decreased by 83.9%\n"
     ]
    }
   ],
   "source": [
    "df_train = reduce_mem_usage(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tournament</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBNOs</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assists</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosts</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>damageDealt</th>\n",
       "      <td>18.453125</td>\n",
       "      <td>119.0</td>\n",
       "      <td>141.125000</td>\n",
       "      <td>763.500</td>\n",
       "      <td>132.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headshotKills</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heals</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killPlace</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killStreaks</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kills</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longestKill</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>173.125</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revives</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rideDistance</th>\n",
       "      <td>6032.000000</td>\n",
       "      <td>6176.0</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>1707.000</td>\n",
       "      <td>3836.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roadKills</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swimDistance</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teamKills</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timeSurvived</th>\n",
       "      <td>1019.500000</td>\n",
       "      <td>983.5</td>\n",
       "      <td>1261.000000</td>\n",
       "      <td>1874.000</td>\n",
       "      <td>1224.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vehicleDestroys</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walkDistance</th>\n",
       "      <td>984.500000</td>\n",
       "      <td>887.0</td>\n",
       "      <td>1259.000000</td>\n",
       "      <td>1346.000</td>\n",
       "      <td>1005.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weaponsAcquired</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winPlace</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teamId</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winPlacePer</th>\n",
       "      <td>0.333252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399902</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.133301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0       1            2         3            4\n",
       "Tournament          1.000000     1.0     8.000000     1.000     2.000000\n",
       "DBNOs               0.000000     0.0     1.000000     4.000     2.000000\n",
       "assists             0.000000     0.0     1.000000     5.000     0.000000\n",
       "boosts              2.000000     0.0    11.000000     7.000     2.000000\n",
       "damageDealt        18.453125   119.0   141.125000   763.500   132.625000\n",
       "headshotKills       0.000000     0.0     0.000000     2.000     0.000000\n",
       "heals               0.000000     0.0    29.000000     3.000     1.000000\n",
       "killPlace          52.000000    62.0    44.000000     2.000    56.000000\n",
       "killStreaks         0.000000     0.0     0.000000     2.000     0.000000\n",
       "kills               0.000000     0.0     0.000000     4.000     0.000000\n",
       "longestKill         0.000000     0.0     0.000000   173.125     0.000000\n",
       "revives             0.000000     1.0     0.000000     0.000     0.000000\n",
       "rideDistance     6032.000000  6176.0  9376.000000  1707.000  3836.000000\n",
       "roadKills           0.000000     0.0     0.000000     0.000     0.000000\n",
       "swimDistance        0.000000     0.0     0.000000     0.000     0.000000\n",
       "teamKills           0.000000     0.0     0.000000     0.000     0.000000\n",
       "timeSurvived     1019.500000   983.5  1261.000000  1874.000  1224.000000\n",
       "vehicleDestroys     0.000000     0.0     0.000000     1.000     0.000000\n",
       "walkDistance      984.500000   887.0  1259.000000  1346.000  1005.500000\n",
       "weaponsAcquired     7.000000     5.0     4.000000     6.000     3.000000\n",
       "winPlace           11.000000    16.0    10.000000     1.000    14.000000\n",
       "teamId             15.000000    13.0     3.000000     6.000    14.000000\n",
       "game               17.000000    50.0    48.000000    23.000    25.000000\n",
       "winPlacePer         0.333252     0.0     0.399902     1.000     0.133301"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(df_train[df_train['winPlacePer'].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGBM(Estimator):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "    \n",
    "    def fit(self, x_train, y_train, x_valid, y_valid):\n",
    "        \n",
    "        lgb_train = lgb.Dataset(data=x_train.astype('float64'), label=y_train.astype('float64'))\n",
    "        lgb_valid = lgb.Dataset(data=x_valid.astype('float64'), label=y_valid.astype('float64'))\n",
    "        \n",
    "        self.lgb_model = lgb.train(self.params, lgb_train, valid_sets=lgb_valid, verbose_eval=1000)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.lgb_model.predict(x.astype('float64'), num_iteration=self.lgb_model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'objective': 'regression',\n",
    "          'metric': 'mae',\n",
    "          'n_estimators': 10000,\n",
    "          'early_stopping_rounds': 100,\n",
    "          'num_leaves': 300,\n",
    "          'max_depth': 14,\n",
    "          'bagging_fraction': 0.8,\n",
    "          'learning_rate': 0.05,\n",
    "          'bagging_seed': 0,\n",
    "          'num_threads': 4,\n",
    "          'colsample_bytree': 0.7,\n",
    "          'verbosity': -1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get group mean feature\n",
      "get group max feature\n",
      "get group min feature\n",
      "get group size feature\n",
      "get match mean feature\n",
      "get match size feature\n",
      "Memory usage of dataframe is 0.85 MB\n",
      "Memory usage after optimization is: 0.28 MB\n",
      "Decreased by 67.1%\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's l1: 0.00236118\n",
      "MAE: 0.0023611773408343906\n",
      "Finished loading model, total used 107 iterations\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's l1: 0.00273723\n",
      "MAE: 0.002737229370881817\n",
      "Finished loading model, total used 112 iterations\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's l1: 0.00284993\n",
      "MAE: 0.0028499285439259523\n",
      "Finished loading model, total used 121 iterations\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's l1: 0.00500141\n",
      "MAE: 0.00500141410760925\n",
      "Finished loading model, total used 103 iterations\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's l1: 0.0157346\n",
      "MAE: 0.01573460069017533\n",
      "Finished loading model, total used 188 iterations\n",
      "Final MAE: 0.005736870010685348\n",
      "Final MSE: 0.00022607176314512118\n",
      "r2: 0.9919166101627159\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "oof, trained_estimators = pipeline_fit(LightGBM(params), df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_train\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5757, 24)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('C:/Users/korn/Desktop/TNI/Paper/Code/test_pubg.csv')\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1.05 MB\n",
      "Memory usage after optimization is: 0.17 MB\n",
      "Decreased by 83.8%\n"
     ]
    }
   ],
   "source": [
    "df_test = reduce_mem_usage(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_id = pd.DataFrame(index=df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get group mean feature\n",
      "get group max feature\n",
      "get group min feature\n",
      "get group size feature\n",
      "get match mean feature\n",
      "get match size feature\n",
      "Memory usage of dataframe is 5.12 MB\n",
      "Memory usage after optimization is: 1.69 MB\n",
      "Decreased by 67.1%\n"
     ]
    }
   ],
   "source": [
    "y = pipeline_predict(trained_estimators, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_test\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = pd.DataFrame()\n",
    "df_oof['lgb_oof'] = oof\n",
    "df_oof.to_csv('light_gbm_oof.csv', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(index=df_test_id.index)\n",
    "df_submission['winPlacePer'] = y\n",
    "df_submission.to_csv('light_gbm_raw.csv', index_label='id')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a35fcbe2881df47f9f7c0447fa00954f027af6c9946c579e1431b3361bf64019"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
