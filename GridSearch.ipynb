{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from copy import deepcopy\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error , r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import gc, sys\n",
    "gc.enable()\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state(message,start = True, time = 0):\n",
    "    if(start):\n",
    "        print(f'Working on {message} ... ')\n",
    "    else :\n",
    "        print(f'Working on {message} took ({round(time , 3)}) Sec \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(is_train=True):\n",
    "    # When this function is used for the training data, load Train_pubg.csv :\n",
    "    if is_train: \n",
    "        print(\"processing Train_pubg.csv\")\n",
    "        df = pd.read_csv('C:/Users/korn/Desktop/TNI/Paper/Code/train_pubg.csv')\n",
    "        \n",
    "    \n",
    "    # When this function is used for the test data, load Test_pubg.csv :\n",
    "    else:\n",
    "        print(\"processing Test_pubg.csv\")\n",
    "        df = pd.read_csv('C:/Users/korn/Desktop/TNI/Paper/Code/test_pubg.csv')\n",
    "\n",
    "\n",
    "    state('totalDistance')\n",
    "    s = timer()\n",
    "    # calculate total distance\n",
    "    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n",
    "    e = timer()\n",
    "    state('totalDistance', False, e - s)\n",
    "          \n",
    "    state('timeSurvived')\n",
    "    s = timer()\n",
    "    df['timeSurvived'] = df['timeSurvived'] \n",
    "    e = timer()\n",
    "    state('timeSurvived', False, e - s)\n",
    "\n",
    "    state('kills')\n",
    "    s = timer()\n",
    "    # calculate total kills and assists\n",
    "    df['kills'] = df['kills'] + (df['assists']/2)\n",
    "    e = timer()\n",
    "    state('kills', False, e - s)\n",
    "\n",
    "    target = 'winPlacePer'\n",
    "    # Get a list of the features to be used\n",
    "    features = list(df.columns)\n",
    "    \n",
    "    y = None\n",
    "    \n",
    "    # If we are processing the training data, process the target\n",
    "    # (group the data by the match and the group then take the mean of the target) \n",
    "    if is_train: \n",
    "        y = np.array(df.groupby(['game','teamId'])[target].agg('mean'), dtype=np.float64)\n",
    "        # Remove the target from the features list :\n",
    "        features.remove(target)\n",
    "    \n",
    "    # Make new features indicating the mean of the features ( grouped by game and teamId ) :\n",
    "    print(\"get group mean feature\")\n",
    "    agg = df.groupby(['game','teamId']).agg('mean')\n",
    "    agg_rank = agg.groupby('game').rank(pct=True).reset_index()\n",
    "    \n",
    "    \n",
    "    # If we are processing the training data let df_out = the grouped  'game' and 'teamId'\n",
    "    if is_train: \n",
    "        df_out = agg.reset_index()[['game','teamId']]\n",
    "    # If we are processing the test data let df_out = 'game' and 'teamId' without grouping \n",
    "    else: \n",
    "        df_out = df[['game','teamId']]\n",
    "    \n",
    "    # Merge agg and agg_rank (that we got before) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['game','teamId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['game','teamId'])\n",
    "    \n",
    "    # Make new features indicating the max value of the features for each group ( grouped by game and teamId )\n",
    "    print(\"get group max feature\")\n",
    "    agg = df.groupby(['game','teamId']).agg('max')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('game').rank(pct=True).reset_index()\n",
    "    \n",
    "    # Merge the new (agg and agg_rank) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['game','teamId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['game','teamId'])\n",
    "    \n",
    "    # Make new features indicating the minimum value of the features for each group ( grouped by game and teamId )\n",
    "    print(\"get group min feature\")\n",
    "    agg = df.groupby(['game','teamId']).agg('min')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('game').rank(pct=True).reset_index()\n",
    "    \n",
    "    # Merge the new (agg and agg_rank) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['game','teamId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['game','teamId'])\n",
    "    \n",
    "    # Make new features indicating the number of players in each group ( grouped by game and teamId )\n",
    "    print(\"get group size feature\")\n",
    "    agg = df.groupby(['game','teamId']).size().reset_index(name='group_size')\n",
    "     \n",
    "    # Merge the group_size feature with df_out :\n",
    "    df_out = df_out.merge(agg, how='left', on=['game','teamId'])\n",
    "    \n",
    "    # Make new features indicating the mean value of each features for each match :\n",
    "    print(\"get match mean feature\")\n",
    "    agg = df.groupby(['game']).agg('mean').reset_index()\n",
    "    \n",
    "    # Merge the new agg with df_out :\n",
    "    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['game'])\n",
    "    \n",
    "    # Make new features indicating the number of groups in each match :\n",
    "    print(\"get match size feature\")\n",
    "    agg = df.groupby(['game']).size().reset_index(name='match_size')\n",
    "    \n",
    "    # Merge the match_size feature with df_out :\n",
    "    df_out = df_out.merge(agg, how='left', on=['game'])\n",
    "    \n",
    "    # Drop game and teamId\n",
    "    df_out.drop([\"game\",\"teamId\"], axis=1, inplace=True)\n",
    "    \n",
    "    # X is the output dataset (without the target) and y is the target :\n",
    "    X = np.array(df_out, dtype=np.float64)\n",
    "    \n",
    "    \n",
    "    del df, df_out, agg, agg_rank\n",
    "    gc.collect()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing Train_pubg.csv\n",
      "Working on totalDistance ... \n",
      "Working on totalDistance took (0.013) Sec \n",
      "\n",
      "Working on timeSurvived ... \n",
      "Working on timeSurvived took (0.0) Sec \n",
      "\n",
      "Working on kills ... \n",
      "Working on kills took (0.008) Sec \n",
      "\n",
      "get group mean feature\n",
      "get group max feature\n",
      "get group min feature\n",
      "get group size feature\n",
      "get match mean feature\n",
      "get match size feature\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 36.2min\n"
     ]
    }
   ],
   "source": [
    "X, y = feature_engineering(True)\n",
    "# X_train, y_train = train_test_split(X,y, test_size = 0.3, random_state = 42)\n",
    "gridParams ={             \n",
    "             'learning_rate ': [0.1,0.01,0.05],\n",
    "             'n_estimatos' : [1000,5000,10000],\n",
    "             'num_leave' : [5,10,100,300],\n",
    "             'boosting_type': ['gbdt','dart','goss','rf'],\n",
    "             'objective': ['mae'],\n",
    "            } \n",
    "\n",
    "mdl = LGBMRegressor(boosting_type= 'gbdt',\n",
    "          objective= 'mae',          \n",
    "          n_estimators= 10000,\n",
    "          num_leaves= 300,\n",
    "          max_depth= 14,\n",
    "          learning2rate= 0.05,\n",
    "          n_jobs= 2,\n",
    "          colsample_bytree= 0.7,\n",
    "          verbose= 2 )   \n",
    "\n",
    "mdl.get_params().keys()\n",
    "\n",
    "grid = GridSearchCV(mdl, gridParams, verbose=2, n_jobs= 2)\n",
    "\n",
    "grid.fit(X,y)\n",
    "\n",
    "print(grid.best_paramas_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = lgb.LGBMClassifier( \n",
    "#     boosting_type=\"gbdt\",\n",
    "#     is_unbalance=True, \n",
    "#     random_state=10, \n",
    "#     n_estimators=50,\n",
    "#     num_leaves=30, \n",
    "#     max_depth=8,\n",
    "#     feature_fraction=0.5,  \n",
    "#     bagging_fraction=0.8, \n",
    "#     bagging_freq=15, \n",
    "#     learning_rate=0.01,    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_opt = {'n_estimators':range(200, 600, 80), 'num_leaves':range(20,60,10)}\n",
    "# gridSearchCV = GridSearchCV(estimator = model, \n",
    "#     param_grid = params_opt, \n",
    "#     scoring='roc_auc',\n",
    "#     n_jobs=4,\n",
    "#     iid=False, \n",
    "#     verbose=1,\n",
    "#     cv=3)\n",
    "# gridSearchCV.fit(X,y)\n",
    "# gridSearchCV.grid_scores_, gridSearchCV.best_params_, gridSearchCV.best_score_"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a35fcbe2881df47f9f7c0447fa00954f027af6c9946c579e1431b3361bf64019"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
